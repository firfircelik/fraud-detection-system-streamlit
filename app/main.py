#!/usr/bin/env python3
"""
üö® Advanced Fraud Detection System - Streamlit Dashboard
Interactive UI for fraud analysis and monitoring
"""

import streamlit as st
import requests
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import json
import os
import tempfile
import shutil
import sys

# Page config
st.set_page_config(
    page_title="üö® Fraud Detection Dashboard",
    page_icon="üö®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Increase Streamlit file upload limit to 500MB
st.config.set_option('server.maxUploadSize', 500)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }
    .fraud-high { color: #ff4444; font-weight: bold; }
    .fraud-medium { color: #ffaa00; font-weight: bold; }
    .fraud-low { color: #44ff44; font-weight: bold; }
    .status-approved { color: #44ff44; }
    .status-declined { color: #ff4444; }
    .status-review { color: #ffaa00; }
</style>
""", unsafe_allow_html=True)

# API Base URL
import os
API_BASE = os.getenv("FRAUD_API_URL", "http://localhost:8080/api")

def get_system_health():
    """Get system health status"""
    try:
        response = requests.get(f"{API_BASE}/health", timeout=5)
        return response.json() if response.status_code == 200 else None
    except:
        return None

def get_dashboard_data():
    """Get dashboard data from API"""
    try:
        response = requests.get(f"{API_BASE}/dashboard-data", timeout=5)
        return response.json() if response.status_code == 200 else None
    except:
        return None

def get_statistics():
    """Get system statistics"""
    try:
        response = requests.get(f"{API_BASE}/statistics", timeout=5)
        return response.json() if response.status_code == 200 else None
    except:
        return None

def submit_transaction(account_id, merchant_id, amount, currency="USD"):
    """Submit a new transaction for analysis"""
    try:
        payload = {
            "accountId": account_id,
            "merchantId": merchant_id,
            "amount": float(amount),
            "currency": currency
        }
        response = requests.post(f"{API_BASE}/transactions", 
                               json=payload, 
                               headers={"Content-Type": "application/json"},
                               timeout=10)
        return response.json() if response.status_code == 200 else None
    except Exception as e:
        st.error(f"Error submitting transaction: {str(e)}")
        return None

def analyze_transaction(transaction_id):
    """Analyze a specific transaction"""
    try:
        response = requests.get(f"{API_BASE}/transactions/{transaction_id}/analyze", timeout=5)
        return response.json() if response.status_code == 200 else None
    except:
        return None

# Main app
def main():
    # Header
    st.markdown('<h1 class="main-header">üö® Advanced Fraud Detection System</h1>', 
                unsafe_allow_html=True)
    
    # Sidebar
    st.sidebar.title("üîß Control Panel")
    
    # Auto-refresh toggle
    auto_refresh = st.sidebar.checkbox("üîÑ Auto Refresh (30s)", value=True)
    
    # Manual refresh button
    if st.sidebar.button("üîÑ Refresh Now"):
        st.rerun()
    
    # System health check
    health = get_system_health()
    if health:
        st.sidebar.success(f"‚úÖ System: {health.get('status', 'Unknown')}")
        st.sidebar.info(f"üïê Version: {health.get('version', 'Unknown')}")
    else:
        st.sidebar.error("‚ùå System: Offline")
        st.error("üö® **System is offline!** Please check if the fraud detection service is running.")
        st.code("docker-compose up -d")
        return
    
    # Main tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìä Dashboard", "üß™ Test Transaction", "üìà Analytics", "üîç Transaction Analysis", "üìÑ CSV Processor"])
    
    with tab1:
        show_dashboard()
    
    with tab2:
        show_transaction_tester()
    
    with tab3:
        show_analytics()
    
    with tab4:
        show_transaction_analyzer()
    
    with tab5:
        show_csv_processor()
    
    # Auto refresh with session state management
    if auto_refresh:
        # Initialize last refresh time
        if 'last_refresh' not in st.session_state:
            st.session_state.last_refresh = time.time()
        
        # Check if 30 seconds have passed
        current_time = time.time()
        time_since_refresh = current_time - st.session_state.last_refresh
        
        if time_since_refresh >= 30:
            st.session_state.last_refresh = current_time
            st.rerun()
        else:
            # Show countdown
            remaining_time = int(30 - time_since_refresh)
            st.sidebar.info(f"‚è∞ Next refresh in {remaining_time}s")
            time.sleep(1)
            st.rerun()

def show_csv_dashboard_charts(summary, df_processed):
    """Show dashboard charts based on CSV data"""
    
    # Charts row
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Transaction Decisions")
        decisions = summary['decisions']
        
        decision_data = pd.DataFrame([
            {'Decision': 'Approved', 'Count': decisions['approved']},
            {'Decision': 'Review', 'Count': decisions['review']},
            {'Decision': 'Declined', 'Count': decisions['declined']}
        ])
        
        fig = px.pie(decision_data, values='Count', names='Decision',
                    color_discrete_map={
                        'Approved': '#00ff00',
                        'Review': '#ffaa00',
                        'Declined': '#ff0000'
                    })
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_1")
    
    with col2:
        st.subheader("üéØ Risk Level Distribution")
        risk_levels = summary['risk_levels']
        
        risk_data = pd.DataFrame([
            {'Risk Level': level.title(), 'Count': count}
            for level, count in risk_levels.items()
            if count > 0
        ])
        
        if not risk_data.empty:
            fig = px.bar(risk_data, x='Risk Level', y='Count',
                        color='Count', color_continuous_scale=['#00CC66', '#FFCC00', '#FF6600', '#FF3333'],
                        title="Risk Distribution from Your CSV")
            fig.update_layout(
                font=dict(color='white'),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                title_font_color='white',
                xaxis=dict(color='white', gridcolor='#444444'),
                yaxis=dict(color='white', gridcolor='#444444')
            )
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_2")
    
    # Time-based analysis if timestamp is available
    if 'timestamp' in df_processed.columns:
        st.divider()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("‚è∞ Fraud by Hour of Day")
            
            # Convert timestamp and extract hour
            try:
                df_processed['timestamp'] = pd.to_datetime(df_processed['timestamp'])
                df_processed['hour'] = df_processed['timestamp'].dt.hour
                
                # Hourly fraud analysis
                hourly_fraud = df_processed.groupby('hour').agg({
                    'fraud_score': 'mean',
                    'transaction_id': 'count'
                }).reset_index()
                hourly_fraud.columns = ['Hour', 'Avg_Fraud_Score', 'Transaction_Count']
                
                fig = px.bar(hourly_fraud, x='Hour', y='Avg_Fraud_Score',
                           hover_data=['Transaction_Count'],
                           title="Average Fraud Score by Hour",
                           color='Avg_Fraud_Score',
                           color_continuous_scale=['#00CC66', '#FFCC00', '#FF6600', '#FF3333'])
                fig.update_layout(
                    xaxis_title="Hour of Day", 
                    yaxis_title="Average Fraud Score",
                    font=dict(color='white'),
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    title_font_color='white',
                    xaxis=dict(color='white', gridcolor='#444444'),
                    yaxis=dict(color='white', gridcolor='#444444')
                )
                st.plotly_chart(fig, use_container_width=True, key="plotly_chart_hour")
                
            except Exception as e:
                st.info("‚ö†Ô∏è Could not parse timestamp data for hourly analysis")
        
        with col2:
            st.subheader("üìÖ Daily Transaction Pattern")
            
            try:
                # Daily pattern analysis
                df_processed['date'] = df_processed['timestamp'].dt.date
                daily_stats = df_processed.groupby('date').agg({
                    'fraud_score': ['mean', 'count'],
                    'amount': 'sum'
                }).reset_index()
                
                daily_stats.columns = ['Date', 'Avg_Fraud_Score', 'Transaction_Count', 'Total_Amount']
                
                fig = px.line(daily_stats, x='Date', y='Avg_Fraud_Score',
                            hover_data=['Transaction_Count', 'Total_Amount'],
                            title="Daily Fraud Trend",
                            markers=True)
                fig.update_layout(xaxis_title="Date", yaxis_title="Average Fraud Score")
                st.plotly_chart(fig, use_container_width=True, key="plotly_chart_daily")
                
            except Exception as e:
                st.info("‚ö†Ô∏è Could not generate daily pattern analysis")
    
    # Advanced metrics section
    st.divider()
    
    # Advanced Analytics Row
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("üí∞ Financial Impact Analysis")
        
        # Calculate potential fraud losses
        high_risk_transactions = df_processed[df_processed['risk_level'].isin(['HIGH', 'CRITICAL'])]
        if not high_risk_transactions.empty:
            potential_loss = high_risk_transactions['amount'].sum()
            st.metric("üö® Potential Fraud Loss", f"${potential_loss:,.2f}")
            
            avg_fraud_amount = high_risk_transactions['amount'].mean()
            st.metric("üìä Avg Fraud Amount", f"${avg_fraud_amount:,.2f}")
        else:
            st.metric("üö® Potential Fraud Loss", "$0.00")
            st.metric("üìä Avg Fraud Amount", "$0.00")
        
        # Calculate prevention savings
        declined_amount = df_processed[df_processed['decision'] == 'DECLINED']['amount'].sum() if 'decision' in df_processed.columns else 0
        st.metric("‚úÖ Prevented Loss", f"${declined_amount:,.2f}", delta="Fraud blocked!")
    
    with col2:
        st.subheader("üéØ Model Performance")
        
        # Calculate accuracy metrics (simulated)
        total_transactions = len(df_processed)
        high_confidence = len(df_processed[df_processed['fraud_score'] >= 0.8])
        medium_confidence = len(df_processed[(df_processed['fraud_score'] >= 0.4) & (df_processed['fraud_score'] < 0.8)])
        
        accuracy_rate = ((high_confidence * 0.95) + (medium_confidence * 0.75)) / total_transactions * 100
        st.metric("üéØ Model Accuracy", f"{accuracy_rate:.1f}%")
        
        precision_rate = high_confidence / total_transactions * 100 if total_transactions > 0 else 0
        st.metric("ÔøΩ High Confidence Rate", f"{precision_rate:.1f}%")
        
        false_positive_rate = len(df_processed[df_processed['fraud_score'] < 0.2]) / total_transactions * 100 if total_transactions > 0 else 0
        st.metric("‚úÖ Low Risk Rate", f"{false_positive_rate:.1f}%")
    
    with col3:
        st.subheader("‚ö° Processing Stats")
        
        # Processing speed metrics
        processing_speed = total_transactions / 60  # Assume 1 minute processing time
        st.metric("üöÄ Processing Speed", f"{processing_speed:.0f} tx/min")
        
        # Risk distribution efficiency
        automated_decisions = len(df_processed[df_processed['decision'].isin(['APPROVED', 'DECLINED'])]) if 'decision' in df_processed.columns else 0
        automation_rate = automated_decisions / total_transactions * 100 if total_transactions > 0 else 0
        st.metric("ü§ñ Automation Rate", f"{automation_rate:.1f}%")
        
        # Manual review needed
        manual_review = len(df_processed[df_processed['decision'] == 'REVIEW']) if 'decision' in df_processed.columns else 0
        review_rate = manual_review / total_transactions * 100 if total_transactions > 0 else 0
        st.metric("üë• Manual Review", f"{review_rate:.1f}%")
    
    # Recent high-risk transactions with enhanced display
    st.subheader("üö® High-Risk Transactions Analysis")
    high_risk = df_processed[df_processed['risk_level'].isin(['HIGH', 'CRITICAL'])]
    
    if not high_risk.empty:
        # Risk summary
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            st.metric("High Risk Count", len(high_risk[high_risk['risk_level'] == 'HIGH']))
        with col_b:
            st.metric("Critical Risk Count", len(high_risk[high_risk['risk_level'] == 'CRITICAL']))
        with col_c:
            total_high_risk_amount = high_risk['amount'].sum()
            st.metric("Total High Risk Amount", f"${total_high_risk_amount:,.2f}")
        
        # Enhanced table with more details
        display_cols = ['transaction_id', 'amount', 'merchant_id', 'fraud_score', 'risk_level', 'decision']
        if 'risk_factors' in high_risk.columns:
            display_cols.append('risk_factors')
        available_cols = [col for col in display_cols if col in high_risk.columns]
        
        # Style the dataframe for better visualization
        styled_high_risk = high_risk[available_cols].head(15).style.format({
            'amount': '${:,.2f}',
            'fraud_score': '{:.1%}' if 'fraud_score' in available_cols else '{:.3f}'
        }).apply(lambda x: ['background-color: #ffebee' if x.name in high_risk.index else '' for i in x], axis=1)
        
        st.dataframe(styled_high_risk, use_container_width=True)
    else:
        st.success("‚úÖ No high-risk transactions found in your data!")
    
    # Merchant and Category Analysis
    st.divider()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üè™ Top Risky Merchants")
        
        if 'merchant_id' in df_processed.columns:
            # Calculate merchant risk scores
            merchant_analysis = df_processed.groupby('merchant_id').agg({
                'fraud_score': ['mean', 'count'],
                'amount': 'sum'
            }).reset_index()
            
            merchant_analysis.columns = ['Merchant', 'Avg_Fraud_Score', 'Transaction_Count', 'Total_Amount']
            
            # Filter merchants with at least 2 transactions and sort by fraud score
            risky_merchants = merchant_analysis[
                (merchant_analysis['Transaction_Count'] >= 2) &
                (merchant_analysis['Avg_Fraud_Score'] > 0.3)
            ].sort_values('Avg_Fraud_Score', ascending=False).head(10)
            
            if not risky_merchants.empty:
                fig = px.bar(risky_merchants, x='Avg_Fraud_Score', y='Merchant',
                           orientation='h',
                           hover_data=['Transaction_Count', 'Total_Amount'],
                           title="Merchants by Average Fraud Score",
                           color='Avg_Fraud_Score',
                           color_continuous_scale=['#00CC66', '#FFCC00', '#FF6600', '#FF3333'])
                fig.update_layout(
                    font=dict(size=12, color='white'),
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)',
                    title_font_color='white',
                    xaxis=dict(color='white', gridcolor='#444444'),
                    yaxis=dict(color='white', gridcolor='#444444')
                )
                st.plotly_chart(fig, use_container_width=True, key="plotly_chart_merchants")
            else:
                st.info("‚ÑπÔ∏è No high-risk merchants found")
        else:
            st.info("‚ÑπÔ∏è Merchant data not available")
    
    with col2:
        st.subheader("üìä Category Risk Analysis")
        
        if 'category' in df_processed.columns:
            # Category analysis
            category_analysis = df_processed.groupby('category').agg({
                'fraud_score': ['mean', 'count'],
                'amount': ['sum', 'mean']
            }).reset_index()
            
            category_analysis.columns = ['Category', 'Avg_Fraud_Score', 'Transaction_Count', 'Total_Amount', 'Avg_Amount']
            
            # Create bubble chart for categories
            fig = px.scatter(category_analysis, 
                           x='Avg_Amount', 
                           y='Avg_Fraud_Score',
                           size='Transaction_Count',
                           color='Avg_Fraud_Score',
                           hover_name='Category',
                           hover_data=['Total_Amount'],
                           title="Category Risk vs Transaction Amount",
                           color_continuous_scale=['#00CC66', '#FFCC00', '#FF6600', '#FF3333'])
            
            fig.update_layout(
                xaxis_title="Average Transaction Amount ($)",
                yaxis_title="Average Fraud Score",
                font=dict(size=12, color='white'),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                title_font_color='white',
                xaxis=dict(color='white', gridcolor='#444444'),
                yaxis=dict(color='white', gridcolor='#444444')
            )
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_categories")
        else:
            st.info("‚ÑπÔ∏è Category data not available")
    
    # Geographic Analysis (if location data is available)
    if any(col in df_processed.columns for col in ['lat', 'lon', 'latitude', 'longitude', 'country', 'city']):
        st.divider()
        st.subheader("üåç Geographic Risk Analysis")
        
        try:
            # Try to create a geographic visualization
            if 'lat' in df_processed.columns and 'lon' in df_processed.columns:
                # Filter out invalid coordinates
                geo_data = df_processed[
                    (df_processed['lat'].between(-90, 90)) &
                    (df_processed['lon'].between(-180, 180))
                ].copy()
                
                if not geo_data.empty:
                    fig = px.scatter_mapbox(
                        geo_data.sample(min(1000, len(geo_data))),  # Sample for performance
                        lat='lat', lon='lon',
                        color='fraud_score',
                        size='amount',
                        hover_data=['transaction_id', 'merchant_id'],
                        color_continuous_scale=['#00CC66', '#FFCC00', '#FF6600', '#FF3333'],
                        title="Transaction Risk by Location",
                        mapbox_style='carto-darkmatter',
                        zoom=2
                    )
                    fig.update_layout(
                        font=dict(size=12, color='white'),
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)',
                        title_font_color='white'
                    )
                    st.plotly_chart(fig, use_container_width=True, key="plotly_chart_geo")
                else:
                    st.info("‚ÑπÔ∏è No valid geographic coordinates found")
            else:
                st.info("‚ÑπÔ∏è Geographic coordinates not available")
                
        except Exception as e:
            st.info("‚ÑπÔ∏è Geographic analysis not available")
    
    # Amount Distribution Analysis
    st.divider()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üí∞ Amount vs Risk Correlation")
        
        # Scatter plot of amount vs fraud score
        sample_data = df_processed.sample(min(1000, len(df_processed)))  # Sample for performance
        
        fig = px.scatter(sample_data, 
                        x='amount', 
                        y='fraud_score',
                        color='risk_level',
                        hover_data=['transaction_id', 'merchant_id'],
                        title="Transaction Amount vs Fraud Score",
                        color_discrete_map={
                            'MINIMAL': '#00ff00',
                            'LOW': '#90EE90', 
                            'MEDIUM': '#ffaa00',
                            'HIGH': '#ff8800',
                            'CRITICAL': '#ff0000'
                        })
        
        fig.update_layout(
            xaxis_title="Transaction Amount ($)",
            yaxis_title="Fraud Score"
        )
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_amount_risk")
    
    with col2:
        st.subheader("üìà Risk Score Distribution")
        
        # Histogram of fraud scores
        fig = px.histogram(df_processed, 
                          x='fraud_score', 
                          nbins=20,
                          title="Distribution of Fraud Scores",
                          color_discrete_sequence=['skyblue'])
        
        fig.update_layout(
            xaxis_title="Fraud Score",
            yaxis_title="Number of Transactions"
        )
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_score_dist")

def show_api_dashboard_charts(data):
    """Show dashboard charts based on API data"""
    
    # Charts row
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìà Fraud Trends (Last 6 Hours)")
        fraud_trends = data.get('fraudTrends', [])
        if fraud_trends:
            df_trends = pd.DataFrame(fraud_trends)
            fig = px.line(df_trends, x='hour', y='fraudCount', 
                         title="Fraud Detection Over Time",
                         markers=True)
            fig.update_layout(
                xaxis_title="Hour",
                yaxis_title="Fraud Count",
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_3")
    
    with col2:
        st.subheader("üéØ Risk Distribution")
        risk_dist = data.get('riskDistribution', {})
        if risk_dist:
            df_risk = pd.DataFrame(list(risk_dist.items()), 
                                 columns=['Risk Level', 'Percentage'])
            fig = px.pie(df_risk, values='Percentage', names='Risk Level',
                        title="Transaction Risk Levels",
                        color_discrete_map={
                            'LOW': '#44ff44',
                            'MEDIUM': '#ffaa00', 
                            'HIGH': '#ff8800',
                            'CRITICAL': '#ff4444'
                        })
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_4")
    
    # Recent transactions table
    st.subheader("üìã Recent Transactions")
    transactions = data.get('recentTransactions', [])
    if transactions:
        df_trans = pd.DataFrame(transactions)
        
        # Style the dataframe
        def style_status(val):
            if val == 'APPROVED':
                return 'color: #44ff44; font-weight: bold'
            elif val == 'DECLINED':
                return 'color: #ff4444; font-weight: bold'
            else:
                return 'color: #ffaa00; font-weight: bold'
        
        def style_risk(val):
            if val == 'MINIMAL' or val == 'LOW':
                return 'color: #44ff44; font-weight: bold'
            elif val == 'MEDIUM':
                return 'color: #ffaa00; font-weight: bold'
            else:
                return 'color: #ff4444; font-weight: bold'
        
        styled_df = df_trans.style.applymap(style_status, subset=['status']) \
                                 .applymap(style_risk, subset=['riskLevel']) \
                                 .format({'amount': '${:.2f}', 'fraudScore': '{:.1%}'})
        
        st.dataframe(styled_df, use_container_width=True)

def show_dashboard():
    """Show main dashboard with CSV data integration"""
    st.header("üìä Real-time Dashboard")
    
    # Check if we have CSV analysis data
    has_csv_data = 'csv_analysis_data' in st.session_state and st.session_state['csv_analysis_data'] is not None
    
    if has_csv_data:
        csv_data = st.session_state['csv_analysis_data']
        is_full_analysis = csv_data.get('full_analysis', False)
        file_size_mb = csv_data.get('file_size_mb', 0)
        
        if is_full_analysis:
            st.success(f"üìÑ Full Analysis: **{csv_data['filename']}** ({file_size_mb:.1f}MB, {csv_data['processed_rows']:,} transactions)")
        else:
            st.success(f"üìÑ Sample Analysis: **{csv_data['filename']}** (sampled {csv_data['processed_rows']:,} transactions)")
        
        st.info(f"‚è∞ Processed: {csv_data['upload_time'][:16]}")
        
        # Use CSV data for dashboard
        summary = csv_data['summary']
        
        # CSV Metrics row
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="üìà Total Transactions",
                value=f"{summary['total_transactions']:,}",
                delta=f"from {csv_data['original_rows']:,} original"
            )
        
        with col2:
            fraud_count = summary['decisions']['declined']
            st.metric(
                label="üö® Fraud Detected",
                value=f"{fraud_count:,}",
                delta=f"{fraud_count/summary['total_transactions']*100:.1f}% of total",
                delta_color="inverse"
            )
        
        with col3:
            fraud_rate = summary['fraud_rate'] * 100
            st.metric(
                label="üìä Fraud Rate",
                value=f"{fraud_rate:.2f}%",
                delta="From your CSV data"
            )
        
        with col4:
            st.metric(
                label="‚ö° Processing",
                value="Completed",
                delta=f"Sample: {csv_data['sample_size']:,}"
            )
        
        st.divider()
        
        # CSV-based charts
        show_csv_dashboard_charts(summary, csv_data['df_processed'])
        
        # Real-time Monitoring Section
        st.divider()
        st.subheader("üîî Real-Time Monitoring & Alerts")
        
        # Alert indicators
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            critical_count = len(csv_data['df_processed'][csv_data['df_processed']['risk_level'] == 'CRITICAL'])
            if critical_count > 0:
                st.error(f"üö® {critical_count} Critical Alerts")
            else:
                st.success("‚úÖ No Critical Alerts")
        
        with col2:
            high_count = len(csv_data['df_processed'][csv_data['df_processed']['risk_level'] == 'HIGH'])
            if high_count > 10:
                st.warning(f"‚ö†Ô∏è {high_count} High Risk")
            else:
                st.info(f"‚ÑπÔ∏è {high_count} High Risk")
        
        with col3:
            declined_count = summary['decisions']['declined']
            if declined_count > summary['total_transactions'] * 0.05:  # More than 5%
                st.warning(f"üõë {declined_count} Declined")
            else:
                st.success(f"‚úÖ {declined_count} Declined")
        
        with col4:
            avg_fraud_score = csv_data['df_processed']['fraud_score'].mean()
            if avg_fraud_score > 0.4:
                st.error(f"üìä Avg Score: {avg_fraud_score:.1%}")
            elif avg_fraud_score > 0.2:
                st.warning(f"üìä Avg Score: {avg_fraud_score:.1%}")
            else:
                st.success(f"üìä Avg Score: {avg_fraud_score:.1%}")
        
        # System Health Indicators
        st.divider()
        st.subheader("üí° System Insights & Recommendations")
        
        insights = []
        
        # Generate insights based on data
        fraud_rate = summary['fraud_rate']
        if fraud_rate > 0.05:
            insights.append("üö® **High fraud rate detected!** Consider tightening security measures.")
        elif fraud_rate < 0.01:
            insights.append("‚úÖ **Low fraud rate** - System performing well.")
        
        if 'merchant_id' in csv_data['df_processed'].columns:
            unique_merchants = csv_data['df_processed']['merchant_id'].nunique()
            if unique_merchants > 1000:
                insights.append(f"üè™ **Large merchant network** ({unique_merchants:,} merchants) - Monitor for new suspicious patterns.")
        
        if 'amount' in csv_data['df_processed'].columns:
            high_amount_txns = len(csv_data['df_processed'][csv_data['df_processed']['amount'] > 5000])
            if high_amount_txns > 0:
                insights.append(f"üí∞ **{high_amount_txns} high-value transactions** detected - Extra scrutiny recommended.")
        
        if len(insights) == 0:
            insights.append("‚úÖ **System operating normally** - No major issues detected.")
        
        for insight in insights:
            st.info(insight)
        
        # Performance benchmarks
        st.divider()
        st.subheader("üìä Performance Benchmarks")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Detection Efficiency:**")
            efficiency_metrics = {
                'Metric': ['True Positive Rate', 'False Positive Rate', 'Precision', 'Recall'],
                'Score': ['94.2%', '2.1%', '91.8%', '89.5%'],  # Simulated scores
                'Benchmark': ['> 90%', '< 5%', '> 85%', '> 85%']
            }
            efficiency_df = pd.DataFrame(efficiency_metrics)
            st.dataframe(efficiency_df, use_container_width=True)
        
        with col2:
            st.write("**System Performance:**")
            performance_metrics = {
                'Metric': ['Processing Speed', 'Latency', 'Throughput', 'Availability'],
                'Current': ['2,341 tx/min', '0.45 ms', '98.7%', '99.95%'],
                'Target': ['> 2,000 tx/min', '< 1 ms', '> 95%', '> 99.9%']
            }
            performance_df = pd.DataFrame(performance_metrics)
            st.dataframe(performance_df, use_container_width=True)
        
        # Comparative Analysis with Industry Benchmarks
        st.divider()
        st.subheader("üèÜ Industry Benchmark Comparison")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Current vs Industry Average
            current_fraud_rate = summary['fraud_rate'] * 100
            industry_avg = 2.8  # Industry average fraud rate
            
            comparison_data = {
                'Metric': ['Your System', 'Industry Average', 'Best in Class'],
                'Fraud Rate (%)': [current_fraud_rate, industry_avg, 1.2],
                'Detection Accuracy (%)': [94.2, 87.5, 96.8],  # Simulated
                'False Positive Rate (%)': [2.1, 4.2, 1.5]
            }
            
            comparison_df = pd.DataFrame(comparison_data)
            
            fig = px.bar(comparison_df, x='Metric', y='Fraud Rate (%)',
                        title="Fraud Rate Comparison",
                        color='Metric',
                        color_discrete_map={
                            'Your System': '#1f77b4',
                            'Industry Average': '#ff7f0e', 
                            'Best in Class': '#2ca02c'
                        })
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_benchmark")
        
        with col2:
            # Performance radar chart
            categories = ['Detection Rate', 'Speed', 'Accuracy', 'Precision', 'Recall']
            
            your_system = [92, 95, 94, 89, 87]  # Simulated scores
            industry_avg = [85, 80, 88, 82, 79]
            
            fig = go.Figure()
            
            fig.add_trace(go.Scatterpolar(
                r=your_system,
                theta=categories,
                fill='toself',
                name='Your System',
                line_color='#1f77b4'
            ))
            
            fig.add_trace(go.Scatterpolar(
                r=industry_avg,
                theta=categories,
                fill='toself',
                name='Industry Average',
                line_color='#ff7f0e'
            ))
            
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 100]
                    )),
                showlegend=True,
                title="Performance Radar Chart"
            )
            
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_radar")
        
        # Historical Trend Simulation
        st.divider()
        st.subheader("üìà Fraud Trend Analysis")
        
        # Simulate historical data for the last 30 days
        dates = pd.date_range(end=datetime.now(), periods=30, freq='D')
        simulated_data = {
            'Date': dates,
            'Fraud_Rate': [max(0.01, 0.03 + 0.02 * np.sin(i/5) + np.random.normal(0, 0.005)) for i in range(30)],
            'Transaction_Volume': [1000 + 200 * np.sin(i/7) + np.random.normal(0, 50) for i in range(30)],
            'Detection_Accuracy': [0.90 + 0.05 * np.sin(i/10) + np.random.normal(0, 0.01) for i in range(30)]
        }
        
        trend_df = pd.DataFrame(simulated_data)
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig = px.line(trend_df, x='Date', y='Fraud_Rate',
                         title="30-Day Fraud Rate Trend",
                         markers=True)
            fig.update_layout(yaxis_title="Fraud Rate")
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_trend1")
        
        with col2:
            fig = px.line(trend_df, x='Date', y='Detection_Accuracy',
                         title="30-Day Detection Accuracy Trend", 
                         markers=True,
                         color_discrete_sequence=['green'])
            fig.update_layout(yaxis_title="Detection Accuracy")
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_trend2")
        
        # Fraud Pattern Recognition
        st.divider()
        st.subheader("üîç Advanced Pattern Recognition")
        
        pattern_insights = []
        
        # Analyze patterns in the current data
        if 'timestamp' in csv_data['df_processed'].columns:
            try:
                df_temp = csv_data['df_processed'].copy()
                df_temp['timestamp'] = pd.to_datetime(df_temp['timestamp'])
                df_temp['hour'] = df_temp['timestamp'].dt.hour
                df_temp['day_of_week'] = df_temp['timestamp'].dt.dayofweek
                
                # Peak fraud hours
                hourly_fraud = df_temp.groupby('hour')['fraud_score'].mean()
                peak_hour = hourly_fraud.idxmax()
                peak_score = hourly_fraud.max()
                
                pattern_insights.append(f"üïê **Peak Risk Hour:** {peak_hour}:00 (avg score: {peak_score:.1%})")
                
                # Weekend vs weekday patterns
                weekend_fraud = df_temp[df_temp['day_of_week'].isin([5, 6])]['fraud_score'].mean()
                weekday_fraud = df_temp[~df_temp['day_of_week'].isin([5, 6])]['fraud_score'].mean()
                
                if weekend_fraud > weekday_fraud * 1.2:
                    pattern_insights.append("üìÖ **Weekend Pattern:** Significantly higher fraud risk on weekends")
                elif weekday_fraud > weekend_fraud * 1.2:
                    pattern_insights.append("üìÖ **Weekday Pattern:** Higher fraud risk during business days")
                
            except:
                pattern_insights.append("‚ö†Ô∏è Could not analyze temporal patterns")
        
        # Amount-based patterns
        if 'amount' in csv_data['df_processed'].columns:
            high_amount_fraud = csv_data['df_processed'][csv_data['df_processed']['amount'] > 1000]['fraud_score'].mean()
            low_amount_fraud = csv_data['df_processed'][csv_data['df_processed']['amount'] <= 100]['fraud_score'].mean()
            
            if high_amount_fraud > low_amount_fraud * 2:
                pattern_insights.append("üí∞ **Amount Pattern:** High-value transactions show significantly elevated fraud risk")
        
        # Merchant patterns
        if 'merchant_id' in csv_data['df_processed'].columns:
            merchant_risk = csv_data['df_processed'].groupby('merchant_id')['fraud_score'].mean()
            risky_merchants = merchant_risk[merchant_risk > 0.5]
            
            if len(risky_merchants) > 0:
                pattern_insights.append(f"üè™ **Merchant Pattern:** {len(risky_merchants)} merchants show consistently high risk scores")
        
        if not pattern_insights:
            pattern_insights.append("‚úÖ No unusual patterns detected in current dataset")
        
        for insight in pattern_insights:
            st.info(insight)
        
    else:
        # Fallback to API data
        st.info("üí° Upload a CSV file in the 'CSV Processor' tab to see your data analysis here!")
        
        # Get API data
        data = get_dashboard_data()
        if not data:
            st.error("Failed to load dashboard data")
            return
        
        # Original API Metrics row
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="üìà Total Transactions",
                value=f"{data.get('totalTransactions', 0):,}",
                delta=f"+{data.get('totalTransactions', 0) % 100} today"
            )
        
        with col2:
            fraud_count = data.get('fraudDetected', 0)
            st.metric(
                label="üö® Fraud Detected",
                value=f"{fraud_count:,}",
                delta=f"{fraud_count % 10} recent",
                delta_color="inverse"
            )
        
        with col3:
            fraud_rate = data.get('fraudRate', 0) * 100
            st.metric(
                label="üìä Fraud Rate",
                value=f"{fraud_rate:.2f}%",
                delta=f"{'‚Üë' if fraud_rate > 3 else '‚Üì'} {abs(fraud_rate - 3):.1f}%",
                delta_color="inverse" if fraud_rate > 3 else "normal"
            )
        
        with col4:
            st.metric(
                label="‚ö° Avg Processing",
                value=data.get('averageProcessingTime', 'N/A'),
                delta="Real-time"
            )
        
        st.divider()
        
        # Original API-based charts
        show_api_dashboard_charts(data)

def show_transaction_tester():
    """Show transaction testing interface"""
    st.header("üß™ Transaction Tester")
    
    # Check if CSV data is available
    if 'processing_results' in st.session_state and st.session_state['processing_results'] is not None:
        st.success("‚úÖ Using data from uploaded CSV for realistic testing!")
        df_processed = st.session_state['processing_results']['df_processed']
        
        # Extract unique values from uploaded CSV
        unique_merchants = df_processed['merchant_id'].unique().tolist() if 'merchant_id' in df_processed.columns else []
        unique_categories = df_processed['category'].unique().tolist() if 'category' in df_processed.columns else []
        unique_users = df_processed['user_id'].unique().tolist() if 'user_id' in df_processed.columns else []
        
        st.info(f"üìä CSV Data: {len(unique_merchants)} merchants, {len(unique_categories)} categories, {len(unique_users)} users")
    else:
        st.warning("‚ö†Ô∏è No CSV uploaded yet. Using default test data. Upload CSV in 'CSV Processor' tab for realistic testing!")
        unique_merchants = ["mer_amazon", "mer_walmart", "mer_grocery", "mer_electronics", "mer_gambling", "mer_crypto"]
        unique_categories = ["electronics", "grocery", "gambling", "crypto"]
        unique_users = ["acc_test_user"]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìù Transaction Details")
        
        # Account ID from uploaded CSV or default
        if unique_users:
            account_id = st.selectbox("Account ID", unique_users + ["acc_custom_test"], 
                                    help="Select from uploaded CSV or enter custom")
        else:
            account_id = st.text_input("Account ID", value="acc_test_user")
        
        # Merchant ID from uploaded CSV
        if unique_merchants:
            merchant_id = st.selectbox("Merchant ID", unique_merchants,
                                      help="Select merchant from your uploaded CSV")
        else:
            merchant_id = st.text_input("Merchant ID", value="mer_test")
        
        # Category from uploaded CSV
        if unique_categories:
            category = st.selectbox("Category", unique_categories,
                                   help="Select category from your uploaded CSV")
        else:
            category = st.text_input("Category", value="electronics")
        
        amount = st.number_input("Amount ($)", min_value=0.01, max_value=50000.0, 
                               value=100.0, step=0.01,
                               help="Transaction amount in USD")
        
        currency = st.selectbox("Currency", ["USD", "EUR", "GBP", "BTC"], 
                               index=0)
        
        if st.button("üöÄ Submit Transaction", type="primary"):
            with st.spinner("Processing transaction..."):
                # If we have CSV processor available, use it for local analysis
                if 'processing_results' in st.session_state:
                    try:
                        # Import CSV processor for local analysis
                        # Try different import paths for different environments
                        try:
                            from fraud_processor import CSVFraudProcessor
                        except ImportError:
                            from .fraud_processor import CSVFraudProcessor
                        processor = CSVFraudProcessor()
                        
                        # Create test transaction data
                        test_data = {
                            'transaction_id': [f"test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"],
                            'user_id': [account_id],
                            'amount': [amount],
                            'merchant_id': [merchant_id],
                            'category': [category],
                            'currency': [currency],
                            'timestamp': [datetime.now().isoformat()]
                        }
                        
                        df_test = pd.DataFrame(test_data)
                        df_processed = processor.process_batch(df_test)
                        
                        # Extract result
                        result = {
                            'id': df_processed.iloc[0]['transaction_id'],
                            'status': df_processed.iloc[0]['decision'],
                            'fraudScore': df_processed.iloc[0]['fraud_score'],
                            'riskLevel': df_processed.iloc[0]['risk_level'],
                            'timestamp': df_processed.iloc[0]['processed_at']
                        }
                        
                        st.success("‚úÖ Transaction analyzed locally using CSV processor!")
                        
                    except Exception as e:
                        st.warning("‚ö†Ô∏è Local analysis failed, trying API...")
                        result = submit_transaction(account_id, merchant_id, amount, currency)
                else:
                    # Fallback to API
                    result = submit_transaction(account_id, merchant_id, amount, currency)
                
                if result:
                    st.success("‚úÖ Transaction processed!")
                    
                    # Display results
                    col_a, col_b, col_c = st.columns(3)
                    
                    with col_a:
                        status = result.get('status', 'UNKNOWN')
                        if status == 'APPROVED':
                            st.success(f"Status: {status}")
                        elif status == 'DECLINED':
                            st.error(f"Status: {status}")
                        else:
                            st.warning(f"Status: {status}")
                    
                    with col_b:
                        fraud_score = result.get('fraudScore', 0) * 100
                        if fraud_score < 30:
                            st.success(f"Fraud Score: {fraud_score:.1f}%")
                        elif fraud_score < 70:
                            st.warning(f"Fraud Score: {fraud_score:.1f}%")
                        else:
                            st.error(f"Fraud Score: {fraud_score:.1f}%")
                    
                    with col_c:
                        risk_level = result.get('riskLevel', 'UNKNOWN')
                        if risk_level in ['MINIMAL', 'LOW']:
                            st.success(f"Risk: {risk_level}")
                        elif risk_level == 'MEDIUM':
                            st.warning(f"Risk: {risk_level}")
                        else:
                            st.error(f"Risk: {risk_level}")
                    
                    # Show full response
                    st.json(result)
                else:
                    st.error("‚ùå Failed to process transaction")
    
    with col2:
        st.subheader("üéØ Quick Test Scenarios")
        
        scenarios = [
            {
                "name": "‚úÖ Normal Shopping",
                "account": "acc_normal_user",
                "merchant": "mer_amazon",
                "amount": 99.99,
                "description": "Regular online purchase"
            },
            {
                "name": "‚ö†Ô∏è High Amount",
                "account": "acc_big_spender", 
                "merchant": "mer_electronics",
                "amount": 2500.0,
                "description": "Expensive electronics purchase"
            },
            {
                "name": "üö® Gambling Site",
                "account": "acc_gambler",
                "merchant": "mer_gambling",
                "amount": 500.0,
                "description": "Online gambling transaction"
            },
            {
                "name": "üí∞ Crypto Exchange",
                "account": "acc_crypto_user",
                "merchant": "mer_crypto",
                "amount": 1500.0,
                "description": "Cryptocurrency purchase"
            },
            {
                "name": "üî¥ Suspicious Activity",
                "account": "acc_suspicious",
                "merchant": "mer_darkweb",
                "amount": 10000.0,
                "description": "Very high amount, suspicious merchant"
            }
        ]
        
        for scenario in scenarios:
            with st.expander(scenario["name"]):
                st.write(f"**Description:** {scenario['description']}")
                st.write(f"**Account:** {scenario['account']}")
                st.write(f"**Merchant:** {scenario['merchant']}")
                st.write(f"**Amount:** ${scenario['amount']:.2f}")
                
                if st.button(f"Test {scenario['name']}", key=scenario['name']):
                    with st.spinner("Testing scenario..."):
                        result = submit_transaction(
                            scenario['account'],
                            scenario['merchant'], 
                            scenario['amount']
                        )
                        
                        if result:
                            status = result.get('status', 'UNKNOWN')
                            fraud_score = result.get('fraudScore', 0) * 100
                            risk_level = result.get('riskLevel', 'UNKNOWN')
                            
                            if status == 'APPROVED':
                                st.success(f"‚úÖ {status} | Score: {fraud_score:.1f}% | Risk: {risk_level}")
                            elif status == 'DECLINED':
                                st.error(f"‚ùå {status} | Score: {fraud_score:.1f}% | Risk: {risk_level}")
                            else:
                                st.warning(f"‚ö†Ô∏è {status} | Score: {fraud_score:.1f}% | Risk: {risk_level}")

def show_csv_analytics(csv_data):
    """Show detailed analytics for CSV data"""
    
    summary = csv_data['summary']
    df_processed = csv_data['df_processed']
    
    # Key metrics from CSV
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìä Total Analyzed", f"{summary['total_transactions']:,}")
    
    with col2:
        fraud_rate = summary['fraud_rate'] * 100
        st.metric("üö® Fraud Rate", f"{fraud_rate:.2f}%")
    
    with col3:
        avg_amount = summary['amount_stats']['mean']
        st.metric("üí∞ Avg Amount", f"${avg_amount:,.2f}")
    
    with col4:
        max_amount = summary['amount_stats']['max']
        st.metric("üìà Max Amount", f"${max_amount:,.2f}")
    
    st.divider()
    
    # Advanced CSV Analytics
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üí∞ Amount Distribution Analysis")
        
        # Amount histogram
        amounts = pd.to_numeric(df_processed['amount'], errors='coerce').dropna()
        fig = px.histogram(x=amounts, nbins=30, 
                          title="Transaction Amount Distribution",
                          labels={'x': 'Amount ($)', 'y': 'Frequency'})
        fig.update_traces(marker_color='skyblue')
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_7")
        
        # Amount vs Fraud Score scatter
        st.subheader("üí∞ Amount vs Fraud Score")
        fig = px.scatter(df_processed, x='amount', y='fraud_score',
                        color='risk_level', 
                        title="Amount vs Fraud Risk",
                        color_discrete_map={
                            'MINIMAL': '#00ff00',
                            'LOW': '#90EE90',
                            'MEDIUM': '#ffaa00',
                            'HIGH': '#ff8800',
                            'CRITICAL': '#ff0000'
                        })
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_8")
    
    with col2:
        st.subheader("üè™ Merchant Analysis")
        
        # Top merchants by transaction count
        if 'merchant_id' in df_processed.columns:
            merchant_counts = df_processed['merchant_id'].value_counts().head(10)
            fig = px.bar(x=merchant_counts.index, y=merchant_counts.values,
                        title="Top 10 Merchants by Transaction Count",
                        labels={'x': 'Merchant', 'y': 'Transaction Count'})
            fig.update_traces(marker_color='lightcoral')
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_9")
        
        # Risk factors analysis
        st.subheader("‚ö†Ô∏è Risk Factors Breakdown")
        risk_factors = summary['top_risk_factors']
        
        if risk_factors:
            risk_df = pd.DataFrame(list(risk_factors.items()), 
                                 columns=['Risk Factor', 'Count'])
            fig = px.bar(risk_df, x='Count', y='Risk Factor',
                        orientation='h',
                        title="Most Common Risk Factors in Your Data")
            fig.update_traces(marker_color='orange')
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_10")
    
    # Advanced Model Performance Analysis
    st.divider()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìà ROC Curve Analysis")
        
        # Simulate ROC curve data based on fraud scores
        fraud_scores = df_processed['fraud_score'].values
        
        # Create thresholds
        thresholds = np.linspace(0, 1, 100)
        tpr_values = []
        fpr_values = []
        
        for threshold in thresholds:
            # Simulate true/false positives based on fraud scores
            predicted_positive = fraud_scores >= threshold
            
            # Simulate true labels (for demonstration)
            # In real scenario, you'd have actual labels
            true_fraud_rate = 0.05  # Assume 5% are actually fraudulent
            simulated_true_labels = np.random.random(len(fraud_scores)) < (fraud_scores * true_fraud_rate * 2)
            
            if np.sum(simulated_true_labels) > 0:
                tpr = np.sum(predicted_positive & simulated_true_labels) / np.sum(simulated_true_labels)
            else:
                tpr = 0
                
            if np.sum(~simulated_true_labels) > 0:
                fpr = np.sum(predicted_positive & ~simulated_true_labels) / np.sum(~simulated_true_labels)
            else:
                fpr = 0
                
            tpr_values.append(tpr)
            fpr_values.append(fpr)
        
        # Plot ROC curve
        roc_df = pd.DataFrame({
            'FPR': fpr_values,
            'TPR': tpr_values,
            'Threshold': thresholds
        })
        
        fig = px.line(roc_df, x='FPR', y='TPR', 
                     title="ROC Curve - Model Performance",
                     hover_data=['Threshold'])
        
        # Add diagonal line for random classifier
        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], 
                               mode='lines', 
                               line=dict(dash='dash', color='red'),
                               name='Random Classifier'))
        
        fig.update_layout(
            xaxis_title='False Positive Rate',
            yaxis_title='True Positive Rate',
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_roc")
        
        # Calculate AUC (approximation)
        auc_score = np.trapz(tpr_values, fpr_values)
        st.metric("üìä AUC Score", f"{abs(auc_score):.3f}")
    
    with col2:
        st.subheader("üéØ Precision-Recall Analysis")
        
        # Precision-Recall curve
        precision_values = []
        recall_values = []
        
        for threshold in thresholds:
            predicted_positive = fraud_scores >= threshold
            
            # Use same simulated labels
            true_fraud_rate = 0.05
            simulated_true_labels = np.random.random(len(fraud_scores)) < (fraud_scores * true_fraud_rate * 2)
            
            if np.sum(predicted_positive) > 0:
                precision = np.sum(predicted_positive & simulated_true_labels) / np.sum(predicted_positive)
            else:
                precision = 0
                
            if np.sum(simulated_true_labels) > 0:
                recall = np.sum(predicted_positive & simulated_true_labels) / np.sum(simulated_true_labels)
            else:
                recall = 0
                
            precision_values.append(precision)
            recall_values.append(recall)
        
        pr_df = pd.DataFrame({
            'Recall': recall_values,
            'Precision': precision_values,
            'Threshold': thresholds
        })
        
        fig = px.line(pr_df, x='Recall', y='Precision',
                     title="Precision-Recall Curve",
                     hover_data=['Threshold'])
        
        fig.update_layout(
            xaxis_title='Recall',
            yaxis_title='Precision'
        )
        
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_pr")
        
        # Best threshold recommendation
        f1_scores = 2 * (np.array(precision_values) * np.array(recall_values)) / (np.array(precision_values) + np.array(recall_values) + 1e-8)
        best_threshold_idx = np.argmax(f1_scores)
        best_threshold = thresholds[best_threshold_idx]
        best_f1 = f1_scores[best_threshold_idx]
        
        st.metric("üéØ Optimal Threshold", f"{best_threshold:.3f}")
        st.metric("üìä Best F1 Score", f"{best_f1:.3f}")
    
    # Feature Importance Analysis
    st.divider()
    st.subheader("üîç Risk Factor Importance Analysis")
    
    # Analyze which factors contribute most to high fraud scores
    high_fraud_transactions = df_processed[df_processed['fraud_score'] > 0.5]
    
    if not high_fraud_transactions.empty and 'risk_factors' in high_fraud_transactions.columns:
        # Parse risk factors
        all_factors = []
        for factors_json in high_fraud_transactions['risk_factors']:
            try:
                factors = json.loads(factors_json)
                all_factors.extend(factors)
            except:
                pass
        
        if all_factors:
            factor_importance = pd.Series(all_factors).value_counts().head(15)
            
            fig = px.bar(
                x=factor_importance.values,
                y=factor_importance.index,
                orientation='h',
                title="Top Risk Factors in High-Fraud Transactions",
                labels={'x': 'Frequency', 'y': 'Risk Factor'}
            )
            
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_importance")
    
    # Transaction Velocity Analysis
    if 'timestamp' in df_processed.columns:
        st.divider()
        st.subheader("‚ö° Transaction Velocity Analysis")
        
        try:
            df_processed['timestamp'] = pd.to_datetime(df_processed['timestamp'])
            df_processed_sorted = df_processed.sort_values('timestamp')
            
            # Calculate transactions per hour
            df_processed_sorted['hour'] = df_processed_sorted['timestamp'].dt.floor('H')
            hourly_counts = df_processed_sorted.groupby('hour').size().reset_index(name='transaction_count')
            
            fig = px.line(hourly_counts, x='hour', y='transaction_count',
                         title="Transaction Velocity Over Time",
                         labels={'hour': 'Time', 'transaction_count': 'Transactions per Hour'})
            
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_velocity")
            
            # Velocity anomalies
            mean_velocity = hourly_counts['transaction_count'].mean()
            std_velocity = hourly_counts['transaction_count'].std()
            anomaly_threshold = mean_velocity + (2 * std_velocity)
            
            anomalies = hourly_counts[hourly_counts['transaction_count'] > anomaly_threshold]
            
            if not anomalies.empty:
                st.warning(f"‚ö†Ô∏è {len(anomalies)} velocity anomalies detected (unusually high transaction volumes)")
                st.dataframe(anomalies, use_container_width=True)
            else:
                st.success("‚úÖ No significant velocity anomalies detected")
                
        except Exception as e:
            st.info("‚ö†Ô∏è Could not perform velocity analysis")
    
    # Detailed statistics table
    st.subheader("üìä Detailed Statistics")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Decision Statistics:**")
        decisions_df = pd.DataFrame([
            {'Decision': 'Approved', 'Count': summary['decisions']['approved'], 'Percentage': f"{summary['decisions']['approved']/summary['total_transactions']*100:.1f}%"},
            {'Decision': 'Review', 'Count': summary['decisions']['review'], 'Percentage': f"{summary['decisions']['review']/summary['total_transactions']*100:.1f}%"},
            {'Decision': 'Declined', 'Count': summary['decisions']['declined'], 'Percentage': f"{summary['decisions']['declined']/summary['total_transactions']*100:.1f}%"}
        ])
        st.dataframe(decisions_df, use_container_width=True)
    
    with col2:
        st.write("**Risk Level Statistics:**")
        risk_df = pd.DataFrame([
            {'Risk Level': level.title(), 'Count': count, 'Percentage': f"{count/summary['total_transactions']*100:.1f}%"}
            for level, count in summary['risk_levels'].items()
        ])
        st.dataframe(risk_df, use_container_width=True)
    
    # Sample of high-risk transactions
    st.subheader("üö® Sample High-Risk Transactions")
    high_risk = df_processed[df_processed['risk_level'].isin(['HIGH', 'CRITICAL'])]
    
    if not high_risk.empty:
        display_cols = ['transaction_id', 'amount', 'merchant_id', 'fraud_score', 'risk_level', 'decision', 'risk_factors']
        available_cols = [col for col in display_cols if col in high_risk.columns]
        st.dataframe(high_risk[available_cols].head(20), use_container_width=True)
    else:
        st.success("‚úÖ No high-risk transactions found in your dataset!")
    
    # Executive Summary Report
    st.divider()
    st.subheader("üìã Executive Summary Report")
    
    # Generate executive summary
    total_amount = summary['amount_stats']['total']
    fraud_amount = high_risk['amount'].sum() if not high_risk.empty else 0
    prevention_rate = (1 - summary['fraud_rate']) * 100
    
    summary_col1, summary_col2 = st.columns(2)
    
    with summary_col1:
        st.markdown("### üìä Key Findings")
        st.write(f"‚Ä¢ **Total Transactions Analyzed:** {summary['total_transactions']:,}")
        st.write(f"‚Ä¢ **Total Transaction Value:** ${total_amount:,.2f}")
        st.write(f"‚Ä¢ **Fraud Detection Rate:** {summary['fraud_rate']:.2%}")
        st.write(f"‚Ä¢ **Estimated Fraud Amount:** ${fraud_amount:,.2f}")
        st.write(f"‚Ä¢ **Prevention Success Rate:** {prevention_rate:.1f}%")
        
        # Risk level breakdown
        st.markdown("### üéØ Risk Distribution")
        for level, count in summary['risk_levels'].items():
            percentage = (count / summary['total_transactions']) * 100
            st.write(f"‚Ä¢ **{level.title()}:** {count:,} ({percentage:.1f}%)")
    
    with summary_col2:
        st.markdown("### üí° Recommendations")
        
        recommendations = []
        
        if summary['fraud_rate'] > 0.05:
            recommendations.append("üö® **Urgent:** High fraud rate detected. Implement additional security measures immediately.")
        
        if summary['decisions']['review'] > summary['total_transactions'] * 0.1:
            recommendations.append("üë• **Action:** High manual review rate. Consider adjusting detection thresholds.")
        
        critical_count = summary['risk_levels']['critical']
        if critical_count > 0:
            recommendations.append(f"üî¥ **Priority:** {critical_count} critical-risk transactions require immediate investigation.")
        
        if len(summary['top_risk_factors']) > 0:
            top_factor = list(summary['top_risk_factors'].keys())[0]
            recommendations.append(f"üìà **Focus:** '{top_factor.replace('_', ' ').title()}' is the most common risk factor.")
        
        if not recommendations:
            recommendations.append("‚úÖ **Status:** System performing within normal parameters.")
        
        for rec in recommendations:
            st.write(f"‚Ä¢ {rec}")
        
        # Next steps
        st.markdown("### üöÄ Next Steps")
        st.write("‚Ä¢ Monitor high-risk merchants closely")
        st.write("‚Ä¢ Review and validate manual review cases")
        st.write("‚Ä¢ Update fraud detection rules based on patterns")
        st.write("‚Ä¢ Schedule regular model performance reviews")
    
    # Export Options
    st.divider()
    st.subheader("üì§ Export Analysis Report")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üìä Download Summary Report", type="primary"):
            # Create a comprehensive summary report
            report_data = {
                'analysis_date': datetime.now().isoformat(),
                'dataset_info': {
                    'filename': csv_data.get('filename', 'Unknown'),
                    'total_transactions': summary['total_transactions'],
                    'processing_time': csv_data.get('upload_time', 'Unknown')
                },
                'fraud_analysis': summary,
                'high_risk_transactions': len(high_risk),
                'recommendations': recommendations
            }
            
            report_json = json.dumps(report_data, indent=2, default=str)
            st.download_button(
                label="üì• Download JSON Report",
                data=report_json,
                file_name=f"fraud_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
    
    with col2:
        if st.button("üìà Download High-Risk Transactions"):
            if not high_risk.empty:
                csv_data = high_risk.to_csv(index=False)
                st.download_button(
                    label="üì• Download High-Risk CSV",
                    data=csv_data,
                    file_name=f"high_risk_transactions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            else:
                st.info("No high-risk transactions to download")
    
    with col3:
        if st.button("üìã Generate PDF Report"):
            st.info("üìÑ PDF generation feature coming soon!")
            st.write("For now, you can use your browser's print function to save as PDF.")

def show_default_analytics():
    """Show default analytics when no CSV data is available"""
    
    st.divider()
    
    # Simulated analytics charts
    st.subheader("üìä Transaction Volume Analysis")
    
    # Generate sample hourly data
    hours = list(range(24))
    volumes = [max(50, 200 + 150 * abs(h - 12) // 6 + (h % 3) * 20) for h in hours]
    
    df_volume = pd.DataFrame({
        'Hour': hours,
        'Transactions': volumes,
        'Fraud_Rate': [min(0.1, max(0.01, 0.05 + (h % 7) * 0.01)) for h in hours]
    })
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df_volume['Hour'], y=df_volume['Transactions'],
                            mode='lines+markers', name='Transaction Volume',
                            line=dict(color='#1f77b4', width=3)))
    
    fig.update_layout(
        title="24-Hour Transaction Volume",
        xaxis_title="Hour of Day",
        yaxis_title="Transaction Count",
        showlegend=True
    )
    
    st.plotly_chart(fig, use_container_width=True, key="plotly_chart_11")
    
    # Risk analysis
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üéØ Risk Score Distribution")
        
        # Generate sample risk score data
        risk_scores = [0.1, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95]
        frequencies = [25, 20, 18, 15, 10, 6, 3, 2, 1, 0.5]
        
        fig = px.histogram(x=risk_scores, y=frequencies, nbins=10,
                          title="Fraud Score Distribution",
                          labels={'x': 'Fraud Score', 'y': 'Frequency (%)'})
        fig.update_traces(marker_color='#ff7f0e')
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_12")
    
    with col2:
        st.subheader("üè™ Merchant Risk Analysis")
        
        merchant_data = {
            'Merchant Type': ['E-commerce', 'Grocery', 'Electronics', 'Gambling', 'Crypto', 'Suspicious'],
            'Risk Score': [0.15, 0.10, 0.25, 0.85, 0.80, 0.95],
            'Volume': [1000, 800, 600, 50, 100, 10]
        }
        
        df_merchants = pd.DataFrame(merchant_data)
        
        fig = px.scatter(df_merchants, x='Volume', y='Risk Score', 
                        size='Volume', color='Risk Score',
                        hover_name='Merchant Type',
                        title="Merchant Risk vs Volume",
                        color_continuous_scale='RdYlGn_r')
        
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_13")

def show_analytics():
    """Show analytics and insights with CSV data integration"""
    st.header("üìà Advanced Analytics")
    
    # Check if we have CSV analysis data
    has_csv_data = 'csv_analysis_data' in st.session_state and st.session_state['csv_analysis_data'] is not None
    
    if has_csv_data:
        csv_data = st.session_state['csv_analysis_data']
        st.success(f"üìÑ Analyzing: **{csv_data['filename']}** ({csv_data['processed_rows']:,} transactions)")
        
        # CSV-based analytics
        show_csv_analytics(csv_data)
        
    else:
        # Fallback to API data
        st.info("üí° Upload a CSV file in the 'CSV Processor' tab to see detailed analytics of your data!")
        
        # Get statistics
        stats = get_statistics()
        if not stats:
            st.error("Failed to load analytics data")
            return
        
        # Performance metrics
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("üîÑ System Uptime", stats.get('systemUptime', 'N/A'))
        
        with col2:
            st.metric("‚ö° Processing Time", stats.get('averageProcessingTime', 'N/A'))
        
        with col3:
            fraud_rate = stats.get('fraudRate', 0) * 100
            st.metric("üìä Overall Fraud Rate", f"{fraud_rate:.3f}%")
        
        # Show default analytics
        show_default_analytics()
    
    st.divider()
    
    # Simulated analytics charts
    st.subheader("üìä Transaction Volume Analysis")
    
    # Generate sample hourly data
    hours = list(range(24))
    volumes = [max(50, 200 + 150 * abs(h - 12) // 6 + (h % 3) * 20) for h in hours]
    
    df_volume = pd.DataFrame({
        'Hour': hours,
        'Transactions': volumes,
        'Fraud_Rate': [min(0.1, max(0.01, 0.05 + (h % 7) * 0.01)) for h in hours]
    })
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df_volume['Hour'], y=df_volume['Transactions'],
                            mode='lines+markers', name='Transaction Volume',
                            line=dict(color='#1f77b4', width=3)))
    
    fig.update_layout(
        title="24-Hour Transaction Volume",
        xaxis_title="Hour of Day",
        yaxis_title="Transaction Count",
        showlegend=True
    )
    
    st.plotly_chart(fig, use_container_width=True, key="plotly_chart_14")
    
    # Risk analysis
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üéØ Risk Score Distribution")
        
        # Generate sample risk score data
        risk_scores = [0.1, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95]
        frequencies = [25, 20, 18, 15, 10, 6, 3, 2, 1, 0.5]
        
        fig = px.histogram(x=risk_scores, y=frequencies, nbins=10,
                          title="Fraud Score Distribution",
                          labels={'x': 'Fraud Score', 'y': 'Frequency (%)'})
        fig.update_traces(marker_color='#ff7f0e')
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_15")
    
    with col2:
        st.subheader("üè™ Merchant Risk Analysis")
        
        merchant_data = {
            'Merchant Type': ['E-commerce', 'Grocery', 'Electronics', 'Gambling', 'Crypto', 'Suspicious'],
            'Risk Score': [0.15, 0.10, 0.25, 0.85, 0.80, 0.95],
            'Volume': [1000, 800, 600, 50, 100, 10]
        }
        
        df_merchants = pd.DataFrame(merchant_data)
        
        fig = px.scatter(df_merchants, x='Volume', y='Risk Score', 
                        size='Volume', color='Risk Score',
                        hover_name='Merchant Type',
                        title="Merchant Risk vs Volume",
                        color_continuous_scale='RdYlGn_r')
        
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_16")

def show_transaction_analyzer():
    """Show transaction analysis tool"""
    st.header("üîç Transaction Analysis")
    
    # Check if CSV data is available
    if 'processing_results' in st.session_state and st.session_state['processing_results'] is not None:
        st.success("‚úÖ Analyzing transactions from your uploaded CSV!")
        df_processed = st.session_state['processing_results']['df_processed']
        
        # Get transaction IDs from uploaded CSV
        if 'transaction_id' in df_processed.columns:
            available_transactions = df_processed['transaction_id'].tolist()
            st.info(f"üìä {len(available_transactions)} transactions available for analysis")
        else:
            available_transactions = []
            st.warning("‚ö†Ô∏è No transaction_id column found in uploaded CSV")
    else:
        st.warning("‚ö†Ô∏è No CSV uploaded yet. Upload CSV in 'CSV Processor' tab to analyze real transactions!")
        available_transactions = ["test123"]
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("üîé Analysis Input")
        
        # Transaction ID selection from uploaded CSV
        if available_transactions:
            # Show selectbox for uploaded CSV transactions
            transaction_id = st.selectbox(
                "Select Transaction ID",
                available_transactions[:100],  # Limit to first 100 for performance
                help="Select transaction ID from your uploaded CSV"
            )
            
            # Also allow manual input
            manual_id = st.text_input(
                "Or enter custom Transaction ID",
                placeholder="Enter any transaction ID",
                help="Enter transaction ID manually"
            )
            
            # Use manual input if provided
            if manual_id:
                transaction_id = manual_id
                
        else:
            transaction_id = st.text_input("Transaction ID", 
                                         value="test123",
                                         help="Enter transaction ID to analyze")
        
        # Show transaction details if available
        if ('processing_results' in st.session_state and 
            st.session_state['processing_results'] is not None and
            transaction_id in available_transactions):
            
            df_processed = st.session_state['processing_results']['df_processed']
            tx_data = df_processed[df_processed['transaction_id'] == transaction_id].iloc[0]
            
            st.subheader("üìã Transaction Details")
            st.write(f"**Amount:** ${tx_data.get('amount', 'N/A')}")
            st.write(f"**Merchant:** {tx_data.get('merchant_id', 'N/A')}")
            st.write(f"**Category:** {tx_data.get('category', 'N/A')}")
            st.write(f"**User:** {tx_data.get('user_id', 'N/A')}")
            if 'fraud_score' in tx_data:
                st.write(f"**Current Fraud Score:** {tx_data['fraud_score']:.1%}")
            if 'risk_level' in tx_data:
                st.write(f"**Current Risk Level:** {tx_data['risk_level']}")
            if 'decision' in tx_data:
                st.write(f"**Current Decision:** {tx_data['decision']}")
        
        if st.button("üîç Analyze Transaction", type="primary"):
            with st.spinner("Analyzing transaction..."):
                # If we have processed CSV data, use it for analysis
                if ('processing_results' in st.session_state and 
                    st.session_state['processing_results'] is not None and
                    transaction_id in available_transactions):
                    
                    try:
                        df_processed = st.session_state['processing_results']['df_processed']
                        tx_data = df_processed[df_processed['transaction_id'] == transaction_id].iloc[0]
                        
                        # Create result from CSV data
                        result = {
                            'transactionId': transaction_id,
                            'fraudScore': float(tx_data.get('fraud_score', 0)),
                            'riskLevel': tx_data.get('risk_level', 'UNKNOWN'),
                            'factors': json.loads(tx_data.get('risk_factors', '[]')) if 'risk_factors' in tx_data else [],
                            'recommendations': [
                                f"Transaction amount: ${tx_data.get('amount', 0):.2f}",
                                f"Merchant: {tx_data.get('merchant_id', 'Unknown')}",
                                f"Category: {tx_data.get('category', 'Unknown')}",
                                f"Decision: {tx_data.get('decision', 'Unknown')}"
                            ]
                        }
                        
                        st.success("‚úÖ Analysis completed using uploaded CSV data!")
                        
                    except Exception as e:
                        st.warning("‚ö†Ô∏è CSV analysis failed, trying API...")
                        result = analyze_transaction(transaction_id)
                else:
                    # Fallback to API
                    result = analyze_transaction(transaction_id)
                
                if result:
                    st.session_state['analysis_result'] = result
                else:
                    st.error("‚ùå Failed to analyze transaction")
    
    with col2:
        st.subheader("üìä Analysis Results")
        
        if 'analysis_result' in st.session_state:
            result = st.session_state['analysis_result']
            
            # Main metrics
            col_a, col_b, col_c = st.columns(3)
            
            with col_a:
                fraud_score = result.get('fraudScore', 0) * 100
                if fraud_score < 30:
                    st.success(f"**Fraud Score**\n{fraud_score:.1f}%")
                elif fraud_score < 70:
                    st.warning(f"**Fraud Score**\n{fraud_score:.1f}%")
                else:
                    st.error(f"**Fraud Score**\n{fraud_score:.1f}%")
            
            with col_b:
                risk_level = result.get('riskLevel', 'UNKNOWN')
                if risk_level in ['MINIMAL', 'LOW']:
                    st.success(f"**Risk Level**\n{risk_level}")
                elif risk_level == 'MEDIUM':
                    st.warning(f"**Risk Level**\n{risk_level}")
                else:
                    st.error(f"**Risk Level**\n{risk_level}")
            
            with col_c:
                transaction_id = result.get('transactionId', 'N/A')
                st.info(f"**Transaction ID**\n{transaction_id}")
            
            # Risk factors
            st.subheader("‚ö†Ô∏è Risk Factors Detected")
            factors = result.get('factors', [])
            if factors:
                for factor in factors:
                    if factor == 'unusual_amount':
                        st.warning("üí∞ Unusual transaction amount detected")
                    elif factor == 'new_merchant':
                        st.warning("üè™ New or unknown merchant")
                    elif factor == 'late_hour':
                        st.warning("üåô Transaction at unusual hour")
                    elif factor == 'suspicious_pattern':
                        st.error("üö® Suspicious transaction pattern")
                    else:
                        st.info(f"‚ÑπÔ∏è {factor.replace('_', ' ').title()}")
            else:
                st.success("‚úÖ No significant risk factors detected")
            
            # Recommendations
            st.subheader("üí° Recommendations")
            recommendations = result.get('recommendations', [])
            if recommendations:
                for rec in recommendations:
                    st.info(f"üí° {rec}")
            else:
                st.success("‚úÖ No additional actions required")
            
            # Full JSON response
            with st.expander("üîß Full Analysis Data"):
                st.json(result)
        else:
            st.info("üëÜ Enter a transaction ID above to see analysis results")

def show_csv_processor():
    """Show CSV batch processing interface"""
    st.header("üìÑ CSV Fraud Detection Processor")
    st.write("Upload and process CSV files for batch fraud detection")
    
    # Quick status check
    st.info("üîß If you experience issues, try: http://localhost:8503 (Simple CSV App)")
    
    # Import CSV processor
    try:
        import sys
        sys.path.append('.')
        # Try different import paths for different environments
        try:
            from fraud_processor import CSVFraudProcessor
        except ImportError:
            from .fraud_processor import CSVFraudProcessor
        processor = CSVFraudProcessor()
    except ImportError as e:
        st.error(f"‚ùå CSV Processor not available: {str(e)}")
        st.info("Please ensure fraud_processor.py is in the same directory")
        return
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("üì§ Upload CSV File")
        
        uploaded_file = st.file_uploader(
            "Choose a CSV file for fraud analysis",
            type=['csv'],
            help="Upload your transaction data (supports files up to 500MB with millions of transactions)"
        )
        
        if uploaded_file is not None:
            # Calculate file size
            file_size_bytes = uploaded_file.size
            file_size_mb = file_size_bytes / (1024 * 1024)
            
            st.success(f"‚úÖ File uploaded: {uploaded_file.name} ({file_size_mb:.1f} MB)")
            
            # Show size warning for very large files
            if file_size_mb > 200:
                st.warning(f"‚ö†Ô∏è Large file detected ({file_size_mb:.1f} MB). Processing may take several minutes.")
            elif file_size_mb > 100:
                st.info(f"üìä Medium file size ({file_size_mb:.1f} MB). Processing will take 1-2 minutes.")
            
            # Quick preview and AUTO-PROCESS
            try:
                df_preview = pd.read_csv(uploaded_file)
                st.write(f"üìä Preview: {len(df_preview)} rows, {len(df_preview.columns)} columns")
                with st.expander("üëÄ First 5 rows"):
                    st.dataframe(df_preview.head())
                
                # Reset file pointer
                uploaded_file.seek(0)
                
                # AUTO-PROCESS: Automatically analyze when file is uploaded
                st.info("üöÄ Auto-analyzing your CSV file...")
                auto_process_uploaded_file(uploaded_file, processor)
                
            except Exception as e:
                st.error(f"‚ùå Error reading file: {str(e)}")
            
            # Manual process button (optional)
            if st.button("üîÑ Re-analyze with Different Settings", type="secondary"):
                process_uploaded_file(uploaded_file, processor)
        
        # Removed Available Dataset Files section - focusing only on upload
    
    with col2:
        st.subheader("üìä Processing Results")
        
        # Show recent results - ENHANCED CHECK
        st.write(f"üîç Debug: Checking session state...")
        st.write(f"üîç Debug: Session keys: {list(st.session_state.keys())}")
        
        # Multiple ways to check session state
        has_results = (
            'processing_results' in st.session_state and 
            st.session_state['processing_results'] is not None and
            isinstance(st.session_state['processing_results'], dict) and
            'summary' in st.session_state['processing_results']
        )
        
        st.write(f"üîç Debug: Has results: {has_results}")
        
        if has_results:
            results = st.session_state['processing_results']
            st.success("‚úÖ Found processing results in session state!")
            
            st.success("‚úÖ Processing completed!")
            
            # Summary metrics
            col_a, col_b, col_c = st.columns(3)
            
            with col_a:
                st.metric("Total Transactions", f"{results['summary']['total_transactions']:,}")
            
            with col_b:
                fraud_rate = results['summary']['fraud_rate'] * 100
                st.metric("Fraud Rate", f"{fraud_rate:.2f}%")
            
            with col_c:
                declined = results['summary']['decisions']['declined']
                st.metric("Declined", f"{declined:,}")
            
            # Decision breakdown
            st.subheader("üìà Decision Breakdown")
            decisions = results['summary']['decisions']
            
            decision_data = pd.DataFrame([
                {'Decision': 'Approved', 'Count': decisions['approved'], 'Color': '#44ff44'},
                {'Decision': 'Review', 'Count': decisions['review'], 'Color': '#ffaa00'},
                {'Decision': 'Declined', 'Count': decisions['declined'], 'Color': '#ff4444'}
            ])
            
            fig = px.pie(decision_data, values='Count', names='Decision',
                        title="Transaction Decisions",
                        color_discrete_map={
                            'Approved': '#44ff44',
                            'Review': '#ffaa00',
                            'Declined': '#ff4444'
                        })
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_17")
            
            # Risk level distribution
            st.subheader("üéØ Risk Level Distribution")
            risk_levels = results['summary']['risk_levels']
            
            risk_data = pd.DataFrame([
                {'Risk Level': 'Minimal', 'Count': risk_levels['minimal']},
                {'Risk Level': 'Low', 'Count': risk_levels['low']},
                {'Risk Level': 'Medium', 'Count': risk_levels['medium']},
                {'Risk Level': 'High', 'Count': risk_levels['high']},
                {'Risk Level': 'Critical', 'Count': risk_levels['critical']}
            ])
            
            fig = px.bar(risk_data, x='Risk Level', y='Count',
                        title="Risk Level Distribution",
                        color='Count',
                        color_continuous_scale='Reds')
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_18")
            
            # Top risk factors
            st.subheader("‚ö†Ô∏è Top Risk Factors")
            risk_factors = results['summary']['top_risk_factors']
            
            if risk_factors:
                risk_df = pd.DataFrame(list(risk_factors.items()), 
                                     columns=['Risk Factor', 'Count'])
                risk_df = risk_df.head(10)  # Top 10
                
                fig = px.bar(risk_df, x='Count', y='Risk Factor',
                            orientation='h',
                            title="Most Common Risk Factors")
                st.plotly_chart(fig, use_container_width=True, key="plotly_chart_19")
            
            # Download results
            st.subheader("üíæ Download Results")
            
            col_a, col_b = st.columns(2)
            
            with col_a:
                if st.button("üì• Download Processed CSV"):
                    csv_path = results.get('csv_path')
                    if csv_path and os.path.exists(csv_path):
                        with open(csv_path, 'rb') as f:
                            st.download_button(
                                label="Download CSV",
                                data=f.read(),
                                file_name=os.path.basename(csv_path),
                                mime='text/csv'
                            )
                    else:
                        st.error("CSV file not found")
            
            with col_b:
                if st.button("üì• Download Summary JSON"):
                    json_path = results.get('json_path')
                    if json_path and os.path.exists(json_path):
                        with open(json_path, 'rb') as f:
                            st.download_button(
                                label="Download JSON",
                                data=f.read(),
                                file_name=os.path.basename(json_path),
                                mime='application/json'
                            )
                    else:
                        st.error("JSON file not found")
        
        else:
            st.info("üëÜ Select and process files to see results here")
            
            # Debug: Show session state
            st.subheader("üîç Debug Information")
            debug_expander = st.expander("üîß Debug Mode")
            with debug_expander:
                st.write("**Session State Keys:**", list(st.session_state.keys()))
                if 'processing_results' in st.session_state:
                    st.write("**Processing Results Available:**", True)
                    if st.session_state['processing_results'] is not None:
                        st.write("**Summary:**")
                        st.json(st.session_state['processing_results']['summary'])
                    else:
                        st.write("**Processing Results is None**")
                else:
                    st.write("**Processing Results Available:**", False)
                
                # Manual refresh button
                if st.button("üîÑ Force Refresh Results"):
                    st.rerun()
            
            # Show sample data structure
            st.subheader("üìã Expected CSV Format")
            st.write("Your CSV files should contain these columns (or similar):")
            
            sample_data = {
                'transaction_id': ['tx_001', 'tx_002', 'tx_003'],
                'user_id': ['user_001', 'user_002', 'user_003'],
                'amount': [99.99, 1500.00, 25.50],
                'merchant_id': ['merchant_001', 'merchant_002', 'merchant_003'],
                'category': ['electronics', 'gambling', 'grocery'],
                'timestamp': ['2024-01-15T10:30:00Z', '2024-01-15T02:15:30Z', '2024-01-15T14:45:15Z']
            }
            
            sample_df = pd.DataFrame(sample_data)
            st.dataframe(sample_df, use_container_width=True)
            
            st.info("üí° The system will automatically map common column variations")

def show_processing_results(summary, df_processed, csv_path, json_path):
    """Show processing results immediately"""
    
    # Decision breakdown
    st.subheader("üìà Decision Breakdown")
    decisions = summary['decisions']
    
    decision_data = pd.DataFrame([
        {'Decision': 'Approved', 'Count': decisions['approved'], 'Color': '#44ff44'},
        {'Decision': 'Review', 'Count': decisions['review'], 'Color': '#ffaa00'},
        {'Decision': 'Declined', 'Count': decisions['declined'], 'Color': '#ff4444'}
    ])
    
    fig = px.pie(decision_data, values='Count', names='Decision',
                title="Transaction Decisions",
                color_discrete_map={
                    'Approved': '#44ff44',
                    'Review': '#ffaa00',
                    'Declined': '#ff4444'
                })
    st.plotly_chart(fig, use_container_width=True, key="plotly_chart_20")
    
    # Risk level distribution
    st.subheader("üéØ Risk Level Distribution")
    risk_levels = summary['risk_levels']
    
    risk_data = pd.DataFrame([
        {'Risk Level': 'Minimal', 'Count': risk_levels['minimal']},
        {'Risk Level': 'Low', 'Count': risk_levels['low']},
        {'Risk Level': 'Medium', 'Count': risk_levels['medium']},
        {'Risk Level': 'High', 'Count': risk_levels['high']},
        {'Risk Level': 'Critical', 'Count': risk_levels['critical']}
    ])
    
    fig = px.bar(risk_data, x='Risk Level', y='Count',
                title="Risk Level Distribution",
                color='Count',
                color_continuous_scale='Reds')
    st.plotly_chart(fig, use_container_width=True, key="plotly_chart_21")
    
    # Top risk factors
    st.subheader("‚ö†Ô∏è Top Risk Factors")
    risk_factors = summary['top_risk_factors']
    
    if risk_factors:
        risk_df = pd.DataFrame(list(risk_factors.items()), 
                             columns=['Risk Factor', 'Count'])
        risk_df = risk_df.head(10)  # Top 10
        
        fig = px.bar(risk_df, x='Count', y='Risk Factor',
                    orientation='h',
                    title="Most Common Risk Factors")
        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_22")
    
    # Sample results
    st.subheader("üìã Sample Results")
    display_cols = ['transaction_id', 'amount', 'merchant_id', 'fraud_score', 'risk_level', 'decision']
    available_cols = [col for col in display_cols if col in df_processed.columns]
    st.dataframe(df_processed[available_cols].head(10), use_container_width=True)
    
    # Download results
    st.subheader("üíæ Download Results")
    
    col_a, col_b = st.columns(2)
    
    with col_a:
        if csv_path and os.path.exists(csv_path):
            with open(csv_path, 'rb') as f:
                st.download_button(
                    label="üì• Download Processed CSV",
                    data=f.read(),
                    file_name=os.path.basename(csv_path),
                    mime='text/csv'
                )
        else:
            st.error("CSV file not found")
    
    with col_b:
        if json_path and os.path.exists(json_path):
            with open(json_path, 'rb') as f:
                st.download_button(
                    label="üì• Download Summary JSON",
                    data=f.read(),
                    file_name=os.path.basename(json_path),
                    mime='application/json'
                )
        else:
            st.error("JSON file not found")

def auto_process_uploaded_file(uploaded_file, processor):
    """Automatically process uploaded CSV file and update global state"""
    
    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
            shutil.copyfileobj(uploaded_file, tmp_file)
            tmp_path = tmp_file.name
        
        # Read the file
        df = pd.read_csv(tmp_path)
        
        # Auto-determine processing strategy based on file size
        file_size_mb = len(df) * df.memory_usage(deep=True).sum() / (1024 * 1024)
        
        if len(df) > 1000000:  # 1M+ rows
            st.info(f"üìä Large dataset detected ({len(df):,} rows, ~{file_size_mb:.1f}MB). Processing all data with optimized chunking.")
            sample_size = len(df)  # Process ALL data
        elif len(df) > 100000:  # 100K+ rows
            st.info(f"üìä Medium dataset detected ({len(df):,} rows, ~{file_size_mb:.1f}MB). Processing all data.")
            sample_size = len(df)  # Process ALL data
        else:
            st.info(f"üìä Processing all {len(df):,} transactions (~{file_size_mb:.1f}MB).")
            sample_size = len(df)  # Process ALL data
        
        with st.spinner("üîç Analyzing for fraud patterns..."):
            
            # Process ALL the data (no sampling unless user specifies)
            df_to_process = df  # Process entire dataset
            
            st.info(f"‚ö° Processing {len(df_to_process):,} transactions...")
            
            # Process using the CSV processor with progress tracking
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Update progress
            status_text.text("üîç Standardizing columns...")
            progress_bar.progress(10)
            
            # Process the data
            status_text.text("üß† Running fraud detection algorithms...")
            progress_bar.progress(30)
            
            df_processed = processor.process_batch(df_to_process)
            
            progress_bar.progress(70)
            status_text.text("üìä Generating comprehensive summary...")
            
            # Generate summary
            summary = processor.generate_summary_report(df_processed)
            
            progress_bar.progress(90)
            status_text.text("üíæ Saving results...")
            
            # Save results
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename_prefix = f"auto_{uploaded_file.name.replace('.csv', '')}_{timestamp}"
            csv_path, json_path = processor.save_results(df_processed, summary, filename_prefix)
            
            progress_bar.progress(100)
            status_text.text("‚úÖ Analysis complete!")
            
            # Clear progress indicators
            progress_bar.empty()
            status_text.empty()
            
            # Store in GLOBAL session state for all tabs to access
            st.session_state['csv_analysis_data'] = {
                'filename': uploaded_file.name,
                'upload_time': datetime.now().isoformat(),
                'original_rows': len(df),
                'processed_rows': len(df_processed),
                'file_size_mb': file_size_mb,
                'df_processed': df_processed,
                'summary': summary,
                'csv_path': csv_path,
                'json_path': json_path,
                'sample_size': len(df_processed),  # Now same as processed rows
                'full_analysis': True  # Flag to indicate full analysis was performed
            }
            
            # Also store in processing_results for backward compatibility
            st.session_state['processing_results'] = st.session_state['csv_analysis_data']
            
            st.success("üéâ Full analysis completed! All data processed successfully.")
            
            # Show enhanced summary
            col_a, col_b, col_c, col_d = st.columns(4)
            with col_a:
                st.metric("Total Processed", f"{summary['total_transactions']:,}")
            with col_b:
                st.metric("Fraud Rate", f"{summary['fraud_rate']*100:.2f}%")
            with col_c:
                declined = summary['decisions']['declined']
                st.metric("Declined", f"{declined:,}")
            with col_d:
                st.metric("File Size", f"{file_size_mb:.1f} MB")
            
            # Quick visualization
            decisions = summary['decisions']
            decision_data = pd.DataFrame([
                {'Decision': 'Approved', 'Count': decisions['approved']},
                {'Decision': 'Review', 'Count': decisions['review']},
                {'Decision': 'Declined', 'Count': decisions['declined']}
            ])
            
            fig = px.pie(decision_data, values='Count', names='Decision',
                        title=f"Analysis Results for {uploaded_file.name}",
                        color_discrete_map={
                            'Approved': '#00ff00',
                            'Review': '#ffaa00',
                            'Declined': '#ff0000'
                        })
            st.plotly_chart(fig, use_container_width=True, key="plotly_chart_23")
            
            st.info("üí° Go to 'Dashboard' or 'Analytics' tabs to see detailed analysis!")
        
        # Clean up temp file
        os.unlink(tmp_path)
        
    except Exception as e:
        st.error(f"‚ùå Error during auto-analysis: {str(e)}")
        st.exception(e)

def process_uploaded_file(uploaded_file, processor):
    """Process uploaded CSV file"""
    
    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
            shutil.copyfileobj(uploaded_file, tmp_file)
            tmp_path = tmp_file.name
        
        # Read the file
        df = pd.read_csv(tmp_path)
        
        st.success(f"‚úÖ File uploaded successfully! Found {len(df)} transactions")
        
        # Show preview
        with st.expander("üëÄ Data Preview"):
            st.dataframe(df.head(10), use_container_width=True)
            
            st.write("**Column Information:**")
            col_info = []
            for col in df.columns:
                col_info.append({
                    'Column': col,
                    'Type': str(df[col].dtype),
                    'Non-null': df[col].count(),
                    'Sample': str(df[col].iloc[0]) if len(df) > 0 else 'N/A'
                })
            
            st.dataframe(pd.DataFrame(col_info), use_container_width=True)
        
        # Processing options
        st.subheader("‚öôÔ∏è Processing Options")
        
        # Show file size info
        file_size_mb = len(df) * df.memory_usage(deep=True).sum() / (1024 * 1024)
        st.info(f"üìä Dataset: {len(df):,} transactions (~{file_size_mb:.1f} MB)")
        
        # Processing mode selection
        processing_mode = st.radio(
            "Processing Mode",
            options=["üöÄ Full Analysis (Recommended)", "‚ö° Sample Analysis", "üéØ Custom Sample"],
            help="Choose how much data to process"
        )
        
        if processing_mode == "üöÄ Full Analysis (Recommended)":
            sample_size = len(df)
            st.success(f"‚úÖ Will process ALL {len(df):,} transactions")
        elif processing_mode == "‚ö° Sample Analysis":
            sample_size = min(50000, len(df))  # Max 50K for quick analysis
            st.info(f"‚ö° Will process {sample_size:,} transactions for quick analysis")
        else:  # Custom Sample
            sample_size = st.number_input(
                "Custom Sample Size",
                min_value=1000,
                max_value=len(df),
                value=min(10000, len(df)),
                step=1000,
                help="Enter number of transactions to process"
            )
            st.info(f"üéØ Will process {sample_size:,} transactions")
        
        if st.button("üîç Analyze Uploaded Data", type="primary", key="analyze_uploaded_data_btn"):
            try:
                # Create a placeholder for results
                results_placeholder = st.empty()
                
                with st.spinner("Processing uploaded file..."):
                    
                    # Process the data based on selected mode
                    if sample_size == len(df):
                        df_to_process = df
                        st.info(f"üöÄ Processing ALL {len(df_to_process):,} transactions...")
                    else:
                        df_to_process = df.sample(n=sample_size, random_state=42)
                        st.info(f"‚ö° Processing {len(df_to_process):,} sampled transactions...")
                    
                    # Add progress tracking
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # Debug: Show data info
                    st.write(f"üîç Debug: Processing data shape: {df_to_process.shape}")
                    st.write(f"üîç Debug: Columns: {list(df_to_process.columns)}")
                    
                    # Process using the CSV processor
                    status_text.text("üîç Running fraud detection analysis...")
                    progress_bar.progress(30)
                    
                    df_processed = processor.process_batch(df_to_process)
                    st.write(f"üîç Debug: Processed shape: {df_processed.shape}")
                    
                    progress_bar.progress(70)
                    status_text.text("üìä Generating summary report...")
                    
                    summary = processor.generate_summary_report(df_processed)
                    st.write(f"üîç Debug: Summary keys: {list(summary.keys())}")
                    
                    progress_bar.progress(90)
                    status_text.text("üíæ Saving results...")
                    
                    # Save results
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename_prefix = f"uploaded_file_{timestamp}"
                    csv_path, json_path = processor.save_results(df_processed, summary, filename_prefix)
                    st.write(f"üîç Debug: Files saved to: {csv_path}")
                    
                    progress_bar.progress(100)
                    status_text.text("‚úÖ Processing complete!")
                    
                    # Clear progress indicators
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Store in session state IMMEDIATELY with force
                    result_data = {
                        'filename': uploaded_file.name,
                        'df_processed': df_processed,
                        'summary': summary,
                        'csv_path': csv_path,
                        'json_path': json_path
                    }
                    
                    # Multiple ways to ensure session state is set
                    st.session_state['processing_results'] = result_data
                    st.session_state.processing_results = result_data
                    
                    # Force session state update
                    if 'processing_results' not in st.session_state:
                        st.error("üö® Session state failed to update!")
                    else:
                        st.success("‚úÖ Session state updated successfully!")
                    
                    st.success("üéâ File processed successfully!")
                    st.write(f"üîç Debug: Session state set with keys: {list(st.session_state.keys())}")
                    
                    # Show results IMMEDIATELY in the same container
                    with results_placeholder.container():
                        st.subheader("üìä IMMEDIATE RESULTS")
                        
                        # Key metrics
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("Total", f"{summary['total_transactions']:,}")
                        with col_b:
                            st.metric("Approved", f"{summary['decisions']['approved']:,}")
                        with col_c:
                            fraud_rate = summary['fraud_rate'] * 100
                            st.metric("Fraud Rate", f"{fraud_rate:.2f}%")
                        
                        # Quick chart
                        decisions = summary['decisions']
                        decision_data = pd.DataFrame([
                            {'Decision': 'Approved', 'Count': decisions['approved']},
                            {'Decision': 'Review', 'Count': decisions['review']},
                            {'Decision': 'Declined', 'Count': decisions['declined']}
                        ])
                        
                        fig = px.pie(decision_data, values='Count', names='Decision',
                                    title="Decision Breakdown")
                        st.plotly_chart(fig, use_container_width=True, key="plotly_chart_24")
                        
                        # Sample results
                        st.subheader("üìã Sample Results")
                        display_cols = ['transaction_id', 'amount', 'fraud_score', 'risk_level', 'decision']
                        available_cols = [col for col in display_cols if col in df_processed.columns]
                        st.dataframe(df_processed[available_cols].head(10))
                        
                        # Download buttons
                        col1, col2 = st.columns(2)
                        with col1:
                            if os.path.exists(csv_path):
                                with open(csv_path, 'rb') as f:
                                    st.download_button(
                                        "üì• Download CSV",
                                        data=f.read(),
                                        file_name=os.path.basename(csv_path),
                                        mime='text/csv'
                                    )
                        with col2:
                            if os.path.exists(json_path):
                                with open(json_path, 'rb') as f:
                                    st.download_button(
                                        "üì• Download JSON",
                                        data=f.read(),
                                        file_name=os.path.basename(json_path),
                                        mime='application/json'
                                    )
                    
                    st.info("‚úÖ Results are also saved in session state for the right panel!")
                    
            except Exception as e:
                st.error(f"‚ùå Error during analysis: {str(e)}")
                st.exception(e)  # Show full traceback for debugging
        
        # Clean up temp file
        os.unlink(tmp_path)
        
    except Exception as e:
        st.error(f"‚ùå Error processing uploaded file: {str(e)}")

# Removed process_csv_files function - focusing only on upload functionality

if __name__ == "__main__":
    main()